{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.layers import Reshape \n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a237a35",
   "metadata": {},
   "source": [
    "making first input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputt = Input(shape=(10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7748cc",
   "metadata": {},
   "source": [
    "making output of x we writing this node as frist its output name than in last \n",
    "\n",
    "we will write the value from which this node is taking output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659cfc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden1 = Dense(128, activation=\"relu\")(inputt)\n",
    "#hidden2 = Dense(64, activation=\"relu\")(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedad77c",
   "metadata": {},
   "source": [
    "Now from this 2nd dense/hidden2 layer we will make a branch or split this into two part output1 and output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output1 = Dense(1, activation=\"sigmoid\")(hidden2)\n",
    "#output2 = Dense(5, activation=\"softmax\")(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model=Model(inputs= inputt,outputs=[output1,output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6aafab",
   "metadata": {},
   "source": [
    "You can also plot the model as a graph: and show_shapes=True used to show input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, \"my_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small data\n",
    "#image_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\Transpher learning and cat-and-dog SIMPLE\\Transpher_learning\\Method_3\\utk_facee\\crop_part1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41298dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big size data\n",
    "image_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\Transpher learning and cat-and-dog SIMPLE\\Transpher_learning\\Method_3\\utk_facee\\UTKFace'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda18d0",
   "metadata": {},
   "source": [
    "joining path between dog,cat folder and i by using path.join\n",
    "\n",
    "listing folders using listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age = []\n",
    "gender = []\n",
    "imgg = []\n",
    "\n",
    "\n",
    "for imagess in os.listdir(image_path):\n",
    "    \n",
    "    img_path = os.path.join(image_path,imagess)\n",
    "    Age.append(int(imagess.split('_')[0]))\n",
    "    gender.append(int(imagess.split('_')[1]))\n",
    "    \n",
    "    img = image.load_img(img_path,target_size=(100, 100))\n",
    "    img = image.img_to_array(img)\n",
    "    #img = img.reshape (1,200,200,3)\n",
    "    imgg.append(img)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(imgg)\n",
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(Age)):\n",
    "    \n",
    "    label = [Age[i],gender[i]]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ad8c0",
   "metadata": {},
   "source": [
    "as we can see both age and gender in same list  but we need both in sepreate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [y[:,0],y[:,1]]\n",
    "#y_train = [y_train[:,0],y_train[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6524af",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top = False,input_shape = (100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bafce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634681b",
   "metadata": {},
   "source": [
    "connecting a flatten layer to resnet last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = resnet.layers[-1].output\n",
    "flatten = Flatten()(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfce949",
   "metadata": {},
   "source": [
    "Now from this flatten layer we will make a branch or split this into two part output1 and output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1778a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(512, activation=\"relu\")(flatten)\n",
    "dense2 = Dense(512, activation=\"relu\")(flatten)\n",
    "\n",
    "dense3 = Dense(512, activation=\"relu\")(dense1)\n",
    "dense4 = Dense(512, activation=\"relu\")(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cc61f",
   "metadata": {},
   "source": [
    "making output layer for classification (gender) and regression (age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d35289",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_regression = Dense(1, activation=\"linear\")(dense3)\n",
    "output_classification = Dense(1, activation=\"sigmoid\")(dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bee6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model=Model(inputs= resnet.input,outputs=[output_regression,output_classification])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165394f",
   "metadata": {},
   "source": [
    "Plotinng model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c17439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(resnet_model, \"resnet_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5523074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing all layers of resnet50 model\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking trainable parameter\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc40db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.compile(loss= ['binary_crossentropy', 'mae'],\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "History = resnet_model.fit(x,y, epochs=100, validation_split=0.2 ,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30abc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.save('gender_age.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('gender_age.h5')\n",
    "\n",
    "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "source=cv2.VideoCapture(0)\n",
    "\n",
    "labels_dict={0:'MAN',1:'NO MASK'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15577857",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "\n",
    "    ret,img=source.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_clsfr.detectMultiScale(gray,1.3,5)  \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e44aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec32ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddd13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
