{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56a9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.layers import Reshape \n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a237a35",
   "metadata": {},
   "source": [
    "making first input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97aa1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputt = Input(shape=(10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7748cc",
   "metadata": {},
   "source": [
    "making output of x we writing this node as frist its output name than in last \n",
    "\n",
    "we will write the value from which this node is taking output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659cfc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden1 = Dense(128, activation=\"relu\")(inputt)\n",
    "#hidden2 = Dense(64, activation=\"relu\")(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedad77c",
   "metadata": {},
   "source": [
    "Now from this 2nd dense/hidden2 layer we will make a branch or split this into two part output1 and output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1268e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output1 = Dense(1, activation=\"sigmoid\")(hidden2)\n",
    "#output2 = Dense(5, activation=\"softmax\")(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5134fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model=Model(inputs= inputt,outputs=[output1,output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918d553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6aafab",
   "metadata": {},
   "source": [
    "You can also plot the model as a graph: and show_shapes=True used to show input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0323d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, \"my_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1467aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small data\n",
    "#image_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\Transpher learning and cat-and-dog SIMPLE\\Transpher_learning\\Method_3\\utk_facee\\crop_part1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41298dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big size data\n",
    "image_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\Transpher learning and cat-and-dog SIMPLE\\Transpher_learning\\Method_3\\utk_facee\\UTKFace'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda18d0",
   "metadata": {},
   "source": [
    "joining path between dog,cat folder and i by using path.join\n",
    "\n",
    "listing folders using listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3acdcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age = []\n",
    "gender = []\n",
    "imgg = []\n",
    "\n",
    "\n",
    "for imagess in os.listdir(image_path):\n",
    "    \n",
    "    img_path = os.path.join(image_path,imagess)\n",
    "    Age.append(int(imagess.split('_')[0]))\n",
    "    gender.append(int(imagess.split('_')[1]))\n",
    "    \n",
    "    img = image.load_img(img_path,target_size=(100, 100))\n",
    "    img = image.img_to_array(img)\n",
    "    #img = img.reshape (1,200,200,3)\n",
    "    imgg.append(img)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b140fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 101,\n",
       " 101,\n",
       " 103,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 111,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e26474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(imgg)\n",
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0b7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(Age)):\n",
    "    \n",
    "    label = [Age[i],gender[i]]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4b48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fbc9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4d4dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100,   1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ad8c0",
   "metadata": {},
   "source": [
    "as we can see both age and gender in same list  but we need both in sepreate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38abb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [y[:,0],y[:,1]]\n",
    "#y_train = [y_train[:,0],y_train[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac6524af",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top = False,input_shape = (100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86bafce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 50, 50, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 25, 25, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 25, 25, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 25, 25, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 25, 25, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 13, 13, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 13, 13, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 13, 13, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 13, 13, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 13, 13, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634681b",
   "metadata": {},
   "source": [
    "connecting a flatten layer to resnet last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3d3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = resnet.layers[-1].output\n",
    "flatten = Flatten()(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfce949",
   "metadata": {},
   "source": [
    "Now from this flatten layer we will make a branch or split this into two part output1 and output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1778a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(512, activation=\"relu\")(flatten)\n",
    "dense2 = Dense(512, activation=\"relu\")(flatten)\n",
    "\n",
    "dense3 = Dense(512, activation=\"relu\")(dense1)\n",
    "dense4 = Dense(512, activation=\"relu\")(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cc61f",
   "metadata": {},
   "source": [
    "making output layer for classification (gender) and regression (age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d35289",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_regression = Dense(1, activation=\"linear\")(dense3)\n",
    "output_classification = Dense(1, activation=\"sigmoid\")(dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3bee6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model=Model(inputs= resnet.input,outputs=[output_regression,output_classification])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165394f",
   "metadata": {},
   "source": [
    "Plotinng model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62c17439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(resnet_model, \"resnet_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5523074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing all layers of resnet50 model\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c883310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 50, 50, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 25, 25, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 25, 25, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 25, 25, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 25, 25, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 13, 13, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3_block1_out (Activation)   (None, 13, 13, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 13, 13, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 13, 13, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 13, 13, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          16777728    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          16777728    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          262656      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            513         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            513         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,669,506\n",
      "Trainable params: 34,081,794\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#checking trainable parameter\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dc40db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.compile(loss= ['binary_crossentropy', 'mae'],\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "927d17ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "245/245 [==============================] - 26s 87ms/step - loss: -344.2358 - dense_4_loss: -344.6835 - dense_5_loss: 0.4477 - dense_4_accuracy: 0.1412 - dense_4_mae: 372.3170 - dense_5_accuracy: 0.5516 - dense_5_mae: 0.4477 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 2/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 3/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 4/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 5/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 6/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 7/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 8/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 9/100\n",
      "245/245 [==============================] - 19s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 10/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 11/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 12/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 13/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 14/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 15/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 16/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 17/100\n",
      "245/245 [==============================] - 19s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 18/100\n",
      "245/245 [==============================] - 19s 79ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 19/100\n",
      "245/245 [==============================] - 19s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 21/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 22/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 23/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 24/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 25/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 26/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 27/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 28/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 29/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 30/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 31/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2790 - dense_4_loss: -345.7253 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 32/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 33/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 34/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 35/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 36/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 37/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 38/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 40/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 41/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 42/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 43/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2794 - dense_4_loss: -345.7257 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 44/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2790 - dense_4_loss: -345.7253 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 45/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 46/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 47/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 48/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 49/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 50/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 51/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 52/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 53/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 54/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 55/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 56/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 57/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 59/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 60/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2903 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 61/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 62/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 63/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 64/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 65/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2790 - dense_4_loss: -345.7253 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 66/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 67/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 68/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 69/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 70/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 71/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 72/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2903 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 73/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 74/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 75/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 76/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 78/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2790 - dense_4_loss: -345.7253 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 79/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 80/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2790 - dense_4_loss: -345.7253 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 81/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 82/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 83/100\n",
      "245/245 [==============================] - 20s 81ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 84/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 85/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2904 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 86/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 87/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2793 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 88/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 89/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 90/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 91/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 92/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 93/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2903 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 94/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 95/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2905 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 97/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7255 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 98/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2791 - dense_4_loss: -345.7254 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2907 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 99/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2792 - dense_4_loss: -345.7256 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n",
      "Epoch 100/100\n",
      "245/245 [==============================] - 20s 80ms/step - loss: -345.2790 - dense_4_loss: -345.7253 - dense_5_loss: 0.4463 - dense_4_accuracy: 0.1421 - dense_4_mae: 393.2906 - dense_5_accuracy: 0.5537 - dense_5_mae: 0.4463 - val_loss: -783.6844 - val_dense_4_loss: -784.1354 - val_dense_5_loss: 0.4509 - val_dense_4_accuracy: 0.0000e+00 - val_dense_4_mae: 366.9456 - val_dense_5_accuracy: 0.5496 - val_dense_5_mae: 0.4509\n"
     ]
    }
   ],
   "source": [
    "History = resnet_model.fit(x,y, epochs=100, validation_split=0.2 ,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30abc20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonuc\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "resnet_model.save('gender_age.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7f3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('gender_age.h5')\n",
    "\n",
    "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "source=cv2.VideoCapture(0)\n",
    "\n",
    "labels_dict={0:'MAN',1:'NO MASK'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15577857",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-081f08ac924b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_clsfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "\n",
    "    ret,img=source.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_clsfr.detectMultiScale(gray,1.3,5)  \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e44aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec32ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddd13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
